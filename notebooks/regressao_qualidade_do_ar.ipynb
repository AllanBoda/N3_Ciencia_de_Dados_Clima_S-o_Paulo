
# Projeto Final de Ciência de Dados: Previsão da Qualidade do Ar (PM2.5)

Este notebook implementa o projeto final de Ciência de Dados, focando na **Regressão** para prever a concentração de Material Particulado Fino (PM2.5) na cidade de São Paulo.

## 1. Fundação do Projeto - O Problema de Negócio

*   **Domínio do Problema**: Monitoramento e Previsão da Qualidade do Ar.
*   **Pergunta de Negócio**: "É possível prever a concentração de PM2.5 em uma estação de monitoramento com base nas concentrações de outros poluentes e na estação de medição?"
*   **Objetivo do Modelo**: Construir um modelo de regressão capaz de estimar a concentração de PM2.5 (variável alvo) com base nas demais variáveis de poluição e na estação de medição.

## 2. Jornada dos Dados - Pipeline e Arquitetura

*   **Origem dos Dados**: Dataset de Qualidade do Ar de São Paulo (`sp_air_quality_clean.csv`).
*   **Dataset**: `sp_air_quality_clean.csv` (localizado na pasta `data/`).

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression, Ridge
from sklearn.tree import DecisionTreeRegressor
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from sklearn.impute import SimpleImputer
import joblib
import os

# Definindo os nomes das colunas
COLUMN_NAMES = ['Datetime', 'Station', 'Benzene', 'CO', 'PM10', 'PM2.5', 'NO2', 'O3', 'SO2', 'Toluene', 'TRS']

# --- CORREÇÃO AQUI ---
# O arquivo está na pasta raiz (conforme sua imagem), então basta colocar o nome dele.
data_path = 'sp_air_quality_clean.csv'
# ---------------------

# Verificação de segurança (opcional, mas ajuda a confirmar se o arquivo está lá)
if not os.path.exists(data_path):
    print(f"Erro: O arquivo '{data_path}' ainda não foi encontrado.")
    print("Verifique se você fez o upload dele na barra lateral esquerda do Colab.")
else:
    # Carregar o dataset
    try:
        df = pd.read_csv(
            data_path,
            names=COLUMN_NAMES,
            header=0 # Remove o cabeçalho original e substitui por COLUMN_NAMES
        )

        print(f"Dataset carregado com sucesso! Número de linhas: {len(df)}")
        print("\nPrimeiras linhas do dataset:")
        display(df.head())

    except Exception as e:
        print(f"Ocorreu um erro ao ler o CSV: {e}")

## 2.1. Limpeza e Transformação (ETL/ELT)

O dataset é considerado "limpo", mas aplicamos o pipeline de pré-processamento para garantir a robustez e preparar os dados para a modelagem.

### Tratamento de Variáveis e Codificação

1.  **Variável Alvo**: `PM2.5`.
2.  **Imputação**: Valores ausentes (se houver) são preenchidos com a **mediana** (numéricas) ou a **moda** (categóricas).
3.  **Codificação Categórica**: A coluna `Station` é codificada usando **One-Hot Encoding** (`pd.get_dummies`).


# Variável alvo
target = 'PM2.5'

# Features: todas exceto Datetime e a própria PM2.5
features = [col for col in df.columns if col not in ['Datetime', target]]

X = df[features]
y = df[target]

# Identificar colunas numéricas e categóricas
numeric_cols = X.select_dtypes(include=['float64', 'int64']).columns
categorical_cols = X.select_dtypes(include=['object']).columns

# Imputação de valores ausentes (se houver)
imputer_numeric = SimpleImputer(strategy='median')
X[numeric_cols] = imputer_numeric.fit_transform(X[numeric_cols])

imputer_categorical = SimpleImputer(strategy='most_frequent')
X[categorical_cols] = imputer_categorical.fit_transform(X[categorical_cols])

# Codificação de Variáveis Categóricas (One-Hot Encoding)
X_encoded = pd.get_dummies(X, drop_first=True)

print("--- Dimensões de X antes e depois do get_dummies ---")
print(f"Formato original de X: {X.shape}")
print(f"Formato de X após codificação: {X_encoded.shape}")
print("\nExemplo das 5 primeiras linhas de X_encoded:")
display(X_encoded.head())


## 2.2. Divisão em Conjuntos de Treino e Teste

Os dados são divididos em 70% para treino e 30% para teste para avaliar a capacidade de generalização do modelo.


X_train, X_test, y_train, y_test = train_test_split(
    X_encoded, y,
    test_size=0.3,
    random_state=42
)

print(f"Tamanho do conjunto de treino (X_train): {X_train.shape[0]} amostras")
print(f"Tamanho do conjunto de teste (X_test): {X_test.shape[0]} amostras")


## 3. O Coração do Projeto - Modelagem e Avaliação Comparativa

### 3.1. Treinamento de Três Modelos de Regressão

Serão treinados três modelos de regressão:
1.  **Regressão Linear** (`LinearRegression`)
2.  **Regressão Ridge** (`Ridge`) - Regularização L2
3.  **Árvore de Decisão para Regressão** (`DecisionTreeRegressor`)

### 3.2. Avaliação com Três Métricas

As métricas escolhidas para avaliação são:
*   **RMSE (Root Mean Squared Error)**: Média quadrática da diferença entre os valores previstos e os valores reais. Penaliza erros maiores.
*   **MAE (Mean Absolute Error)**: Média do valor absoluto da diferença entre os valores previstos e os valores reais.
*   **R² (R-squared)**: Coeficiente de determinação. Indica a proporção da variância na variável dependente que é previsível a partir das variáveis independentes.


# Inicializar modelos
models = {
    "Linear Regression": LinearRegression(),
    "Ridge Regression": Ridge(random_state=42),
    "Decision Tree Regressor": DecisionTreeRegressor(random_state=42)
}

results = {}

# Treinar e avaliar cada modelo
for name, model in models.items():
    print(f"\nTreinando {{name}}...")
    model.fit(X_train, y_train)
    predictions = model.predict(X_test)

    # Calcular métricas
    rmse = np.sqrt(mean_squared_error(y_test, predictions))
    mae = mean_absolute_error(y_test, predictions)
    r2 = r2_score(y_test, predictions)

    results[name] = {
        "RMSE": rmse,
        "MAE": mae,
        "R2": r2
    }
    print(f"  RMSE: {{rmse:.4f}}")
    print(f"  MAE: {{mae:.4f}}")
    print(f"  R2: {{r2:.4f}}")

# 3.3. Análise Comparativa dos Resultados
results_df = pd.DataFrame(results).T
print("\n--- Tabela Comparativa de Resultados ---")
display(results_df.sort_values(by='RMSE'))

# Escolher o melhor modelo (menor RMSE)
best_model_name = results_df['RMSE'].idxmin()
best_model = models[best_model_name]
print(f"\nO melhor modelo é: {{best_model_name}} com RMSE de {{results_df.loc[best_model_name, 'RMSE']:.4f}}")


## 4. Tornando o Modelo Útil - Deploy

### 4.1. Salvando o Modelo Treinado

O melhor modelo é salvo no formato `.pkl` na raiz do projeto para ser reutilizado.

### 4.2. Carregando e Utilizando o Modelo

Demonstração de como carregar o modelo salvo e fazer uma previsão em um novo dado.


# 4.1. Salvando o Modelo Treinado
best_model_name = results_df['RMSE'].idxmin()
best_model = models[best_model_name]
model_filename = 'modelo_final.pkl'

joblib.dump(best_model, model_filename)
print(f"Modelo salvo como: {{model_filename}}")

# 4.2. Carregando e Utilizando o Modelo
# Carregar o modelo salvo
loaded_model = joblib.load(model_filename)
print(f"Modelo carregado com sucesso!")

# Criar um novo dado de exemplo (usando o primeiro dado de teste como base)
new_data_example = X_test.iloc[0:1]

# Fazer a previsão
predicted_pm25 = loaded_model.predict(new_data_example)[0]
actual_pm25 = y_test.iloc[0]

print("\n--- Previsão em um Novo Dado ---")
print("Características do Novo Ponto de Medição (Encoded):")
display(new_data_example)
print(f"PM2.5 Real (para comparação): {{actual_pm25:.2f}} µg/m³")
print(f"PM2.5 Previsto pelo Modelo: {{predicted_pm25:.2f}} µg/m³")
print("\nO modelo carregado previu a concentração de PM2.5 com base nas demais variáveis.")
